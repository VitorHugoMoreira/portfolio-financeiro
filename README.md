# portfolio-financeiro

# Pipeline de ConcessÃµes de CrÃ©dito no Azure

## DescriÃ§Ã£o do Projeto
Este projeto implementa um **pipeline completo de dados** utilizando **Azure Data Factory** e **Azure Databricks** para ingestÃ£o, processamento e anÃ¡lise de dados de concessÃµes de crÃ©dito.  

O objetivo foi simular um cenÃ¡rio real de anÃ¡lise bancÃ¡ria, utilizando dados pÃºblicos do **Banco Central do Brasil**, garantindo confiabilidade, governanÃ§a e escalabilidade na arquitetura.  

A soluÃ§Ã£o envolveu:
- **IngestÃ£o** de dados de ambientes **on-premises** e nuvem com o **Azure Data Factory**.  
- **Processamento distribuÃ­do** com **PySpark** no **Databricks**, armazenando dados em **Delta Lake**.  
- **AnÃ¡lises SQL** e exploraÃ§Ã£o de insights diretamente no Databricks.  
- **Versionamento de notebooks** e integraÃ§Ã£o com **DevOps**, assegurando boas prÃ¡ticas de governanÃ§a.  

---

## Tecnologias e Ferramentas
- **Azure Data Factory** â†’ OrquestraÃ§Ã£o e ingestÃ£o de dados  
- **Azure Databricks** â†’ Processamento e anÃ¡lise distribuÃ­da  
- **Delta Lake** â†’ Armazenamento confiÃ¡vel e escalÃ¡vel  
- **PySpark / Spark SQL** â†’ TransformaÃ§Ã£o de dados  
- **Azure Data Lake Storage Gen2** â†’ Data Lake em nuvem  
- **Integration Runtime** â†’ ConexÃ£o com dados on-premises  
- **Azure DevOps + GitHub** â†’ Versionamento e automaÃ§Ã£o  

---

## Dataset Utilizado
Utilizei o conjunto **â€œConcessÃµes de crÃ©dito - Totalâ€** do Banco Central do Brasil, que contÃ©m dados sobre operaÃ§Ãµes de crÃ©dito contratadas no Sistema Financeiro Nacional.  

ğŸ“ Link: [ConcessÃµes de CrÃ©dito - Banco Central](https://dadosabertos.bcb.gov.br/dataset/20631-concessoes-de-credito---total)

Formato: **CSV**

---

## Pipeline do Projeto

### 1 - IngestÃ£o com Azure Data Factory
- **Linked Services**: conexÃ£o com SQL Server on-premises e Azure Blob Storage  
- **Datasets**: representando tabelas e arquivos de saÃ­da  
- **Pipelines**: movimentaÃ§Ã£o dos dados para o Data Lake (camadas *raw/bronze*)  

### 2 - Processamento com Azure Databricks
```python
# Leitura dos dados raw
df = spark.read.csv("/mnt/datalake/raw/concessoes_credito.csv", header=True, inferSchema=True)

# Limpeza e transformaÃ§Ã£o
from pyspark.sql.functions import col, to_date, date_format
df_clean = df.withColumn("Data", to_date(col("Data"), "yyyy-MM-dd"))
df_clean = df_clean.withColumn("AnoMes", date_format(col("Data"), "yyyy-MM"))

# Armazenamento em Delta Lake
df_clean.write.format("delta").mode("overwrite").save("/mnt/datalake/bronze/concessoes_credito_delta")
````

### 3 - AnÃ¡lise com SQL no Databricks

```sql
-- Registrar tabela Delta
CREATE TABLE concessoes_credito
USING DELTA
LOCATION '/mnt/datalake/bronze/concessoes_credito_delta';

-- Volume de crÃ©dito concedido por mÃªs
SELECT AnoMes, SUM(Valor) AS TotalConcedido
FROM concessoes_credito
GROUP BY AnoMes
ORDER BY AnoMes;
```

### 4 - VisualizaÃ§Ã£o

* GrÃ¡ficos no Databricks para evoluÃ§Ã£o do crÃ©dito concedido ao longo do tempo
* Insights extraÃ­dos de consultas SQL e anÃ¡lises interativas

---

## Insights Obtidos

* **Sazonalidade**: padrÃµes mensais nas concessÃµes de crÃ©dito
* **Impacto EconÃ´mico**: influÃªncia de eventos macroeconÃ´micos nas concessÃµes
* **EficiÃªncia Operacional**: ganho de escalabilidade e governanÃ§a com Delta Lake

---

## Possibilidades Futuras

* **IntegraÃ§Ã£o com Power BI** â†’ dashboards interativos
* **AutomaÃ§Ã£o de Jobs** no Databricks â†’ execuÃ§Ã£o periÃ³dica
* **Machine Learning** â†’ uso do MLflow para anÃ¡lise de risco de crÃ©dito

---

## Estrutura do Projeto

```
azure-pipeline-concessoes-credito/
â”‚â”€â”€ README.md
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_ingestao_raw.py
â”‚   â”œâ”€â”€ 02_transformacao_bronze.py
â”‚   â””â”€â”€ 03_analise_credito.sql
â”‚
â”œâ”€â”€ pipelines_adf/
â”‚   â”œâ”€â”€ linked_services.json
â”‚   â”œâ”€â”€ datasets.json
â”‚   â””â”€â”€ pipeline_movimentacao.json
â”‚
â””â”€â”€ data/
    â”œâ”€â”€ raw/       # CSV original
    â””â”€â”€ bronze/    # Dados tratados em Delta Lake
```

---

## Links

* [Portal de Dados Abertos do Banco Central](https://dadosabertos.bcb.gov.br/)
* [DocumentaÃ§Ã£o Azure Data Factory](https://learn.microsoft.com/azure/data-factory/)
* [DocumentaÃ§Ã£o Azure Databricks](https://learn.microsoft.com/azure/databricks/)

---

**Resumo:** Este projeto mostra a construÃ§Ã£o de um pipeline moderno de dados no Azure, cobrindo **ingestÃ£o, processamento, anÃ¡lise, versionamento e governanÃ§a**.
```
